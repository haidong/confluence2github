:::::::::::: {#page}
:::::::: {#main .aui-page-panel}
:::: {#main-header}
::: {#breadcrumb-section}
1.  [Alex Ji](index.html)
2.  [Alex Ji's Home](377815074.html)
3.  [CCO and CSAAS environment sanity
    checks](CCO-and-CSAAS-environment-sanity-checks_389729349.html)
:::

# [ Alex Ji : Remove Rancher from demo environment ]{#title-text} {#title-heading .pagetitle}
::::

::::: {#content .view}
::: page-metadata
Created by [ Alex Ji]{.author}, last modified on Feb 21, 2024
:::

::: {#main-content .wiki-content .group}
Rancher was adapted by team members who no longer work here.
([Rancher](https://confluence.corp.appdynamics.com/display/SALESENG/Rancher))
We\'ve had more trouble upgrading and maintaining it. Besides, our own
CCO solution provides some, if not all, functions Rancher is supposed to
provide. So we decided to remove it.

For removal, in Rancher documentation,
[https://ranchermanager.docs.rancher.com/faq/rancher-is-no-longer-needed](https://ranchermanager.docs.rancher.com/faq/rancher-is-no-longer-needed){.external-link
rel="nofollow"} it recommends a tool called Rancher cleanup:
[https://github.com/rancher/rancher-cleanup](https://github.com/rancher/rancher-cleanup){.external-link
rel="nofollow"}. That\'s what I used. Here are steps I took to remove
Rancher from demo-dev. I\'ll use the same methods to demo1/2/3/4.

1.  I picked an EC2 instance with no prior kubenetes configuration, just
    so the ./kube/config files won\'t be a factor during my operation.
    More importantly, I want to be able to access the k8s cluster
    without using Rancher. I used one Ubuntu instance I built for Cisco
    Live 2024 EMEA, since it had no kubectl config at all. I installed
    aws and kubectl tools on it;
2.  After gaining CLI access to demo aws account, I generated the
    ./kube/config file using:
    `aws eks --region us-west-2 update-kubeconfig --name demo-west-appdcloud-dev` 
3.  I then verified that I could connect by running `kubectl get pods` 
    commands. I also inspected ./kube/config to be sure it has no traces
    of Rancher
4.  On my work laptop, I cloned the rancher-cleanup tool.
5.  On my work laptop, I ran
    `kubectl create -f deploy/rancher-cleanup.yaml` 
6.  While the above step is running, on a separate terminal, I tried to
    follow the log:
    `kubectl  -n kube-system logs -l job-name=cleanup-job  -f` , but
    this command produced
    `Error from server (InternalError): an error on the server ("error trying to reach service: cluster agent disconnected") has prevented the request from succeeding (get pods)`
    . I think this is because I ran the command on work laptop. It
    should have been run on the Ubuntu instance mentioned above, because
    work laptop ./kube/config has dependency on Rancher\
    Indeed running on my laptop with the name registered in Rancher was
    the problem. During the removal of demo1, my laptop\'s .kube/config
    does not use the Rancher shorthand name. And I was able to follow
    the log files fine.
7.  Regardless, this seemed to succeed. All `cattle*` namespaces were
    removed. In
    [https://rancher2.demo.appdynamics.com/dashboard/home](https://rancher2.demo.appdynamics.com/dashboard/home){.external-link
    rel="nofollow"}, the \`[demo-west-appdcloud-dev\` cluster shows not
    available.]{style="color: rgb(20,20,25);"}
8.  [And I can connect to this cluster using its full aws name:
    `arn:aws:eks:us-west-2:632713433352:cluster/demo-west-appdcloud-dev` ]{style="color: rgb(20,20,25);"}
9.  [The CCO UI shows that it keeps receiving logs from the
    cluster.]{style="color: rgb(20,20,25);"}

[I\'ll follow the same steps for the other clusters. I\'ll also make
necessary change in our ad-ecommerce code
repo.]{style="color: rgb(20,20,25);"}
:::
:::::
::::::::

::::: {#footer role="contentinfo"}
:::: {.section .footer-body}
Document generated by Confluence on May 22, 2024 14:04

::: {#footer-logo}
[Atlassian](https://www.atlassian.com/)
:::
::::
:::::
::::::::::::
